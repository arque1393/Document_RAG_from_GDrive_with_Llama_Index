{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AritraRanjanChowdhury\\GEN_AI\\Intelligent_Document_Finder_with_Llama_Index\\.llama_index_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.readers.google import GoogleDriveReader\n",
    "loader = GoogleDriveReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GoogleDriveReader in module llama_index.readers.google.drive.base:\n",
      "\n",
      "class GoogleDriveReader(llama_index.core.readers.base.BaseReader)\n",
      " |  GoogleDriveReader(credentials_path: str = 'credentials.json', token_path: str = 'token.json', pydrive_creds_path: str = 'creds.txt') -> None\n",
      " |  \n",
      " |  Google drive reader.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GoogleDriveReader\n",
      " |      llama_index.core.readers.base.BaseReader\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, credentials_path: str = 'credentials.json', token_path: str = 'token.json', pydrive_creds_path: str = 'creds.txt') -> None\n",
      " |      Initialize with parameters.\n",
      " |  \n",
      " |  load_data(self, folder_id: str = None, file_ids: List[str] = None, mime_types: List[str] = None) -> List[llama_index.core.schema.Document]\n",
      " |      Load data from the folder id and file ids.\n",
      " |      \n",
      " |      Args:\n",
      " |          folder_id: folder id of the folder in google drive.\n",
      " |          file_ids: file ids of the files in google drive.\n",
      " |          mime_types: the mimeTypes you want to allow e.g.: \"application/vnd.google-apps.document\"\n",
      " |      Returns:\n",
      " |          List[Document]: A list of documents.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from llama_index.core.readers.base.BaseReader:\n",
      " |  \n",
      " |  lazy_load_data(self, *args: Any, **load_kwargs: Any) -> Iterable[llama_index.core.schema.Document]\n",
      " |      Load data from the input directory lazily.\n",
      " |  \n",
      " |  load_langchain_documents(self, **load_kwargs: Any) -> List[ForwardRef('LCDocument')]\n",
      " |      Load data in LangChain document format.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from llama_index.core.readers.base.BaseReader:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GoogleDriveReader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method load_data in module llama_index.readers.google.drive.base:\n",
      "\n",
      "load_data(folder_id: str = None, file_ids: List[str] = None, mime_types: List[str] = None) -> List[llama_index.core.schema.Document] method of llama_index.readers.google.drive.base.GoogleDriveReader instance\n",
      "    Load data from the folder id and file ids.\n",
      "    \n",
      "    Args:\n",
      "        folder_id: folder id of the folder in google drive.\n",
      "        file_ids: file ids of the files in google drive.\n",
      "        mime_types: the mimeTypes you want to allow e.g.: \"application/vnd.google-apps.document\"\n",
      "    Returns:\n",
      "        List[Document]: A list of documents.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(loader.load_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-ZGC-6UZC_lq_iImaW4nvgFct_jlWpJEZhHwKJHS6Mc\n",
      "1Dte8R_SjzzQtoq5go8l0I9--U9P5fssdvusSGyiqAw4\n",
      "1qSzKrTyj30SUy93zN03st2f8CFBGeScRUZ0ogGb-P3E\n",
      "1ce7wdv5LO8nWHbx-TnjVn7N-b4w4IUmRmB6NuOZSqj4\n",
      "1TGiETOFt86El-hI4FbE5lYjo65Cw_l5b6yjKlvl7TVg\n"
     ]
    }
   ],
   "source": [
    "def load_data(folder_id: str):\n",
    "    docs = loader.load_data(folder_id=folder_id)\n",
    "    for doc in docs:\n",
    "        # print(doc.metadata)\n",
    "        print(doc.id_)\n",
    "    return docs\n",
    "\n",
    "\n",
    "docs = load_data(folder_id=\"1RFhr3-KmOZCR5rtp4dlOMNl3LKe1kOA5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Drive API Experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files:\n",
      "Example (1XRYcaHI_5nrg_Ht82hF9q42wuzVbtmqZUtUecNlsx14)\n",
      "Storage (1sLmLETXRAUA1NAoJDf6TxnJ21SJiXzQ3)\n",
      "Llama_Index_Data_Retriever (1fyXW1wVWpfn6isaGAcYEFRNBQlQbGRLG)\n",
      "workspace.json (12AMj8sIjQn5SUm_m2Ov2dVc3aeVFpSRt)\n",
      "community-plugins.json (1dhnLlfbpqTAyySZXDRESro48w3wfDtea)\n",
      "core-plugins-migration.json (1b58eFIStIsaiA-vhdQ9y13Eq1pswDfqB)\n",
      "core-plugins.json (1Un9UDfv-wkpI7vKuG853OakyWLoPes-A)\n",
      "data.json (1CmgpShmDhqcdHpYUdbfMhEzNvwyIZ_HN)\n",
      "data.json (1ioKNPhTFXa5ZjvkE6Z2_gB2XzMB8Yvb9)\n",
      "data.json (1KScy5Yj4Guu81olNk_F-uMfOXlNufHY8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# If modifying these scopes, delete the file token.json.\n",
    "CLIENT_SECRET = 'client_secret_944885290760-eol8kggkm9kv1bgmlpvisr619v2mk4ul.apps.googleusercontent.com.json'\n",
    "\n",
    "credential=None\n",
    "SCOPES = [\"https://www.googleapis.com/auth/drive.metadata.readonly\"]\n",
    "if os.path.exists(\"token.json\"):\n",
    "  credential = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
    "# If there are no (valid) credentials available, let the user log in.\n",
    "if not credential or not credential.valid:\n",
    "  if credential and credential.expired and credential.refresh_token:\n",
    "    credential.refresh(Request())\n",
    "  else:\n",
    "    flow = InstalledAppFlow.from_client_secrets_file(\n",
    "        CLIENT_SECRET, SCOPES\n",
    "    )\n",
    "    credential = flow.run_local_server(port=0)\n",
    "  # Save the credentials for the next run\n",
    "  with open(\"token.json\", \"w\") as token:\n",
    "    token.write(credential.to_json())\n",
    "\n",
    "try:\n",
    "  service = build(\"drive\", \"v3\", credentials=credential)\n",
    "\n",
    "  # Call the Drive v3 API\n",
    "  results = (\n",
    "      service.files()\n",
    "      .list(pageSize=10, fields=\"nextPageToken, files(id, name)\")\n",
    "      .execute()\n",
    "  )\n",
    "  items = results.get(\"files\", [])\n",
    "\n",
    "  if not items:\n",
    "    print(\"No files found.\")\n",
    "  else:\n",
    "    print(\"Files:\")\n",
    "    for item in items:\n",
    "      print(f\"{item['name']} ({item['id']})\")\n",
    "except HttpError as error:\n",
    "  # TODO(developer) - Handle errors from drive API.\n",
    "  print(f\"An error occurred: {error}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AritraRanjanChowdhury\\GEN_AI\\Document_RAG_from_GDrive_with_Llama_Index\\WebService\\.llama_ndex_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.schema import BaseNode\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "from llama_index.core import StorageContext, VectorStoreIndex \n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from constants import EMBED_MODEL\n",
    "\n",
    "from typing import Union,Sequence,Optional\n",
    "from pathlib import Path \n",
    "\n",
    "\n",
    "class ChromaVectorStoreIndex(object):\n",
    "    '''This class is a simple control tool for ChromaDB \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,nodes:Sequence[BaseNode],persist_dir : Union[Path,str], collection:str='default',**kwargs):    \n",
    "       \n",
    "        _persist_dir:str = persist_dir if type(persist_dir)==str else persist_dir.resolve().__str__()\n",
    "        self.chroma_client = chromadb.PersistentClient(path=_persist_dir)\n",
    "        self.chroma_collection = self.chroma_client.get_or_create_collection(collection)\n",
    "        self.chroma_vector_store = ChromaVectorStore(chroma_collection=self.chroma_collection)    \n",
    "        if 'embed_model' not in kwargs :\n",
    "            kwargs['embed_model'] = EMBED_MODEL\n",
    "        kwargs['nodes']=nodes\n",
    "        kwargs['storage_context']=StorageContext.from_defaults(\n",
    "                vector_store=self.chroma_vector_store) \n",
    "        print(_persist_dir)\n",
    "        self.__index = VectorStoreIndex(**kwargs)\n",
    "      \n",
    "    def get_chroma_index(self):\n",
    "        return self.__index\n",
    "    \n",
    "    def load_vector_store(self, persist_dir:Union[Path,str], collection_name:str,embed_model:Optional[BaseEmbedding]=None) :\n",
    "        print(\"Create create_index_from_documents call Chroma Vector Store\")\n",
    "        \n",
    "        _persist_dir:str = persist_dir if type(persist_dir)==str else persist_dir.resolve().__str__()        \n",
    "        client = chromadb.PersistentClient(path=_persist_dir)\n",
    "        chroma_collection = client.get_or_create_collection(collection_name)\n",
    "        vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "        if not embed_model:\n",
    "            embed_model = EMBED_MODEL\n",
    "        index =VectorStoreIndex.from_vector_store(\n",
    "            vector_store,\n",
    "            embed_model=embed_model)\n",
    "        self.__index = index\n",
    "\n",
    "\n",
    "# lOADING TEXT AFTER SELECT \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.google import GoogleDriveReader\n",
    "from constants import GOOGLE_CREDENTIALS_PATH\n",
    "loader = GoogleDriveReader(credentials_path=GOOGLE_CREDENTIALS_PATH)\n",
    "\n",
    "def load_data_from_drive_folder(folder_id: str):\n",
    "    docs = loader.load_data(folder_id=folder_id)\n",
    "    if not docs :\n",
    "        raise Exception(\"Content Load Error\",\"No content is loaded\")\n",
    "        \n",
    "    return docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import DRIVE_FOLDER_ID,VECTOR_STORE_PATH\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AritraRanjanChowdhury\\GEN_AI\\Document_RAG_from_GDrive_with_Llama_Index\\WebService\\ChromaDB\n",
      "Create create_index_from_documents call Chroma Vector Store\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "    documents = load_data_from_drive_folder(DRIVE_FOLDER_ID)    \n",
    "    node_parser = SentenceSplitter(chunk_size=1024, chunk_overlap=20)\n",
    "\n",
    "    nodes = node_parser.get_nodes_from_documents(\n",
    "        documents, show_progress=False\n",
    "    )\n",
    "    # print(nodes)\n",
    "    chroma_index = ChromaVectorStoreIndex(nodes,persist_dir=VECTOR_STORE_PATH, collection='Set1')\n",
    "    index = chroma_index.get_chroma_index()\n",
    "    # print(\"****************************************************\",index)\n",
    "    index2 = chroma_index.load_vector_store(persist_dir=VECTOR_STORE_PATH, collection_name ='Set1')\n",
    "    print(index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method as_chat_engine in module llama_index.core.indices.base:\n",
      "\n",
      "as_chat_engine(chat_mode: llama_index.core.chat_engine.types.ChatMode = <ChatMode.BEST: 'best'>, llm: Union[str, llama_index.core.llms.llm.LLM, ForwardRef('BaseLanguageModel'), NoneType] = None, **kwargs: Any) -> llama_index.core.chat_engine.types.BaseChatEngine method of llama_index.core.indices.vector_store.base.VectorStoreIndex instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(index.as_chat_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method as_query_engine in module llama_index.core.indices.base:\n",
      "\n",
      "as_query_engine(llm: Union[str, llama_index.core.llms.llm.LLM, ForwardRef('BaseLanguageModel'), NoneType] = None, **kwargs: Any) -> llama_index.core.base.base_query_engine.BaseQueryEngine method of llama_index.core.indices.vector_store.base.VectorStoreIndex instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(index.as_query_engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method as_retriever in module llama_index.core.indices.vector_store.base:\n",
      "\n",
      "as_retriever(**kwargs: Any) -> llama_index.core.base.base_retriever.BaseRetriever method of llama_index.core.indices.vector_store.base.VectorStoreIndex instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(index.as_retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
